#주성분분석(PCA)

# 국어,영어,수학,과학 점수
x1<-c(26,46,57,36,57,26,58,37,36,56,78,95,88,90,52,56)
x2<-c(35,74,73,73,62,22,67,34,22,42,65,88,90,85,46,66)
x3<-c(35,76,38,69,25,25,87,79,36,26,22,36,58,36,25,44)
x4<-c(45,89,54,55,33,45,67,89,47,36,40,56,68,45,37,56)

score = cbind(x1, x2, x3, x4)
colnames(score) = c("국어","영어","수학","과학")
rownames(score) = 1:16
head(score)

# prcomp: 주성분분석
result = prcomp(score)
result
# PC1 or x1(변수명)--> 첫번째 주성분 분산값
# 국어,PC1: w값. 설명이 잘되는 애들은 w가 크다.
# PC1= 0.6093268 * 국어 + 0.7185749 * 영어 +...
# 국어와 영어는 상관계수 값이 크다
# -> 국어와 영어점수가 높고 낮은 학생들은 PC1으로 설명할 수가 있다.
# PC2는 반대. 국어와 영어는 설명이 안 되고, 수학과 과학이 높고 낮은 학생들은 설명 가능
# 가장 좋은 모델은 PC1와 PC2를 직각으로 떨어트려서 직각에서 찾는다.

summary(result)
# standard deviation; 분산값 -> PC1, PC2는 수치가 높음. 신뢰가 가능함.
# cumulative proportion: 전체 데이터를 PC1이 얼마나 설명을 하는지 누적하여 보여준다.(PC3=PC1+PC2+PC3)
# 누적비율은 보통 80%정도 되는게 일반적이다.

biplot(result)
# 빨간 선기준으로 오른쪽은 영어,국어 높고(양의정수) 왼쪽은 낮은 값(음의정수)
# 가운데 몰린 학생들은 전반적인 과목에서 평균점수
# 설명할 때는 original vector를 보고 적용해서 설명한다.

screeplot(result, npcs=4, type="lines", main="Score")
